{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import key_value_bottleneck.core as kv_core\n",
    "import tqdm\n",
    "from einops import rearrange\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "from kv_bottleneck_experiments.utils.model import CodebookVotingLogitsDecoder\n",
    "from addict import Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### First, we define a few helper functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Copied from here: https://jwalton.info/Embed-Publication-Matplotlib-Latex/\n",
    "def set_size(width, fraction=1):\n",
    "    \"\"\"Set figure dimensions to avoid scaling in LaTeX.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    width: float\n",
    "            Document textwidth or columnwidth in pts\n",
    "    fraction: float, optional\n",
    "            Fraction of the width which you wish the figure to occupy\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    fig_dim: tuple\n",
    "            Dimensions of figure in inches\n",
    "    \"\"\"\n",
    "    # Width of figure (in pts)\n",
    "    fig_width_pt = width * fraction\n",
    "\n",
    "    # Convert from pt to inches\n",
    "    inches_per_pt = 1 / 72.27\n",
    "\n",
    "    # Golden ratio to set aesthetic figure height\n",
    "    # https://disq.us/p/2940ij3\n",
    "    ratio = 1.3\n",
    "\n",
    "    # Figure width in inches\n",
    "    fig_width_in = fig_width_pt * inches_per_pt\n",
    "    # Figure height in inches\n",
    "    fig_height_in = fig_width_in * ratio\n",
    "\n",
    "    fig_dim = (fig_width_in, fig_height_in)\n",
    "\n",
    "    return fig_dim\n",
    "\n",
    "def generate_plot(input_xy, prediction_xy, title, dir_path, file_name, samples_of_tasks=None):\n",
    "    if samples_of_tasks is None:\n",
    "        samples_of_tasks = []\n",
    "    width = 398\n",
    "    fig, ax = plt.subplots(1, 1, figsize=set_size(width, fraction=0.16))\n",
    "    plt.style.use('seaborn')\n",
    "    tex_fonts = {\n",
    "       \"text.usetex\": True,\n",
    "       \"font.family\": \"serif\",\n",
    "       \"axes.labelsize\": 8,\n",
    "       \"axes.titlesize\": 6,\n",
    "       \"font.size\": 8,\n",
    "       \"legend.fontsize\": 8,\n",
    "       \"xtick.labelsize\": 8,\n",
    "       \"ytick.labelsize\": 8\n",
    "    }\n",
    "\n",
    "    plt.rcParams.update(tex_fonts)\n",
    "\n",
    "    ax.scatter(input_xy[:,0, 0], input_xy[:,0, 1], s=0.5, marker=\"s\", cmap=\"Set2\", c=prediction_xy.detach().numpy(), vmin=0, vmax=8)\n",
    "    for task_id in samples_of_tasks:\n",
    "        train_inputs, targets = get_train_stream_data(task_id)\n",
    "        ax.scatter(train_inputs[:, 0, 0], train_inputs[:, 0, 1], cmap=\"Set2\", edgecolors=\"black\", s=2, c=targets.detach().numpy(), vmin=0, vmax=8)\n",
    "    ax.set_xlabel(\"$x_1$\")\n",
    "    ax.set_ylabel(\"$x_2$\")\n",
    "    ax.set_xlim(0.05, 0.95)\n",
    "    ax.set_ylim(0.05, 0.95)\n",
    "    ax.set_aspect(1.0)\n",
    "    ax.set_axis_off()\n",
    "    ax.set_title(title)\n",
    "    pathlib.Path(dir_path).mkdir(parents=True, exist_ok=True)\n",
    "    fig.savefig(f\"{dir_path}/{file_name}.pdf\", format='pdf')\n",
    "    plt.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2D toy domain data loading functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def sample_key_init_data(n_samples):\n",
    "    return torch.rand(n_samples, 2)\n",
    "\n",
    "def get_train_stream_data(task_id, n_samples=100):\n",
    "    \"\"\"\n",
    "    Returns samples from a class_incremental data stream that comprises 8 classes with each task covering 2 classes.\n",
    "    \"\"\"\n",
    "    tasks = [{\"classes\": [0, 4],\n",
    "              \"means\": [[0.25, 0.25], [0.75, 0.5]],\n",
    "              \"std\": [[0.035, 0.035], [0.035, 0.035]],},\n",
    "             {\"classes\": [1, 5],\n",
    "              \"means\": [[0.75, 0.25], [0.5, 0.75]],\n",
    "              \"std\": [[0.035, 0.035], [0.035, 0.035]],},\n",
    "             {\"classes\": [2, 6],\n",
    "              \"means\": [[0.75, 0.75], [0.25, 0.5]],\n",
    "              \"std\": [[0.035, 0.035], [0.035, 0.035]],},\n",
    "             {\"classes\": [3, 7],\n",
    "              \"means\": [[0.25, 0.75], [0.5, 0.25]],\n",
    "              \"std\": [[0.035, 0.035], [0.035, 0.035]],}]\n",
    "\n",
    "    # generate data\n",
    "    n_dim = 2\n",
    "    x = np.zeros((n_samples, n_dim))\n",
    "    y = np.zeros(n_samples)\n",
    "    for i in range(n_samples):\n",
    "        class_id = np.random.choice([0,1])\n",
    "        x[i, 0] = torch.normal(mean=torch.tensor(tasks[task_id][\"means\"][class_id][0]), std=torch.tensor(tasks[task_id][\"std\"][class_id][0]))\n",
    "        x[i, 1] = torch.normal(mean=torch.tensor(tasks[task_id][\"means\"][class_id][1]), std=torch.tensor(tasks[task_id][\"std\"][class_id][1]))\n",
    "        y[i] = tasks[task_id][\"classes\"][class_id]\n",
    "    return torch.tensor(x, dtype=torch.float32)[:, None, :], torch.tensor(y, dtype=torch.int64)\n",
    "\n",
    "def get_grid_samples_from_unit_square(num_samples_per_dim=100):\n",
    "    xs = torch.linspace(0, 1, steps=num_samples_per_dim)\n",
    "    ys = torch.linspace(0, 1, steps=num_samples_per_dim)\n",
    "    x, y = torch.meshgrid(xs, ys, indexing='xy')\n",
    "    xy_tensor = torch.stack([torch.flatten(x)[:, None], torch.flatten(y)[:, None]], dim=-1)\n",
    "    return xy_tensor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Model helper functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class KVModel(torch.nn.Module):\n",
    "    def __init__(self, bottlenecked_encoder, decoder, args):\n",
    "        super().__init__()\n",
    "        self.bottlenecked_encoder = bottlenecked_encoder\n",
    "        self.decoder = decoder\n",
    "        self.args = args\n",
    "\n",
    "    def forward(self, x):\n",
    "        bottleneck_tuple = self.bottlenecked_encoder(x)\n",
    "        x = bottleneck_tuple[0]\n",
    "        x = self.decoder(x=x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### MLP baseline: Let's first investigating the behaviour of a naive MLP"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_mlp = nn.Sequential(nn.Linear(2, 32),\n",
    "                          nn.ReLU(),\n",
    "                          nn.Linear(32, 8))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We first plot the decision boundaries of this randomly initialized mlp model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%capture\n",
    "xy_tensor = get_grid_samples_from_unit_square()\n",
    "model_mlp_predictions = torch.argmax(model_mlp(xy_tensor[:, 0, :]), dim=-1)\n",
    "generate_plot(input_xy=xy_tensor,\n",
    "              prediction_xy=model_mlp_predictions,\n",
    "              title=\"MLP - after init\",\n",
    "              dir_path=\"../artefacts/toy_experiment\",\n",
    "              file_name=\"mlp_predictions_after_init\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, we'll see how the decision boundaries change when trained on the data stream"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%capture\n",
    "model_mlp.train()\n",
    "model_state_dicts = []\n",
    "for task_id in range(4):\n",
    "    optimizer_model_mlp = torch.optim.Adam(model_mlp.parameters(), lr=0.001)\n",
    "    train_inputs, targets = get_train_stream_data(task_id)\n",
    "    for epoch in range(1000):\n",
    "        optimizer_model_mlp.zero_grad()\n",
    "        outputs = model_mlp(train_inputs[:, 0, :])\n",
    "        loss = nn.CrossEntropyLoss()(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer_model_mlp.step()\n",
    "    model_state_dicts.append(deepcopy(model_mlp.state_dict()))\n",
    "\n",
    "model_mlp_predictions_trained = []\n",
    "for task_id in range(4):\n",
    "    model_mlp.load_state_dict(model_state_dicts[task_id])\n",
    "    model_mlp_predictions_trained.append(torch.argmax(model_mlp(xy_tensor[:, 0, :]), dim=-1))\n",
    "    generate_plot(input_xy=xy_tensor,\n",
    "                  prediction_xy=model_mlp_predictions_trained[task_id],\n",
    "                  title=f\"MLP - after $D_{task_id+1}$\",\n",
    "                  dir_path=\"../artefacts/toy_experiment\",\n",
    "                  file_name=f\"mlp_predictions_after_k_{task_id+1}\",\n",
    "                  samples_of_tasks=[task_id])\n",
    "\n",
    "#Plot the final decision boundaries including all visited task sample\n",
    "generate_plot(input_xy=xy_tensor,\n",
    "              prediction_xy=model_mlp_predictions_trained[-1],\n",
    "              title=f\"MLP - final\",\n",
    "              dir_path=\"../artefacts/toy_experiment\",\n",
    "              file_name=\"mlp_final_decision_boundaries\",\n",
    "              samples_of_tasks=[0, 1, 2, 3])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, we'll repeat the same with linear probe only"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%capture\n",
    "model_lp = nn.Sequential(nn.Linear(2, 8))\n",
    "xy_tensor = get_grid_samples_from_unit_square()\n",
    "model_mlp_predictions = torch.argmax(model_lp(xy_tensor[:, 0, :]), dim=-1)\n",
    "generate_plot(input_xy=xy_tensor,\n",
    "              prediction_xy=model_mlp_predictions,\n",
    "              title=\"LP - after init\",\n",
    "              dir_path=\"../artefacts/toy_experiment\",\n",
    "              file_name=\"lp_predictions_after_init\")\n",
    "model_mlp.train()\n",
    "model_state_dicts = []\n",
    "for task_id in range(4):\n",
    "    optimizer_model_lp = torch.optim.Adam(model_lp.parameters(), lr=0.01)\n",
    "    train_inputs, targets = get_train_stream_data(task_id)\n",
    "    for epoch in range(1000):\n",
    "        optimizer_model_lp.zero_grad()\n",
    "        outputs = model_lp(train_inputs[:, 0, :])\n",
    "        loss = nn.CrossEntropyLoss()(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer_model_lp.step()\n",
    "    model_state_dicts.append(deepcopy(model_lp.state_dict()))\n",
    "\n",
    "model_lp_predictions_trained = []\n",
    "for task_id in range(4):\n",
    "    model_lp.load_state_dict(model_state_dicts[task_id])\n",
    "    model_lp_predictions_trained.append(torch.argmax(model_lp(xy_tensor[:, 0, :]), dim=-1))\n",
    "    generate_plot(input_xy=xy_tensor,\n",
    "                  prediction_xy=model_lp_predictions_trained[task_id],\n",
    "                  title=f\"LP - after $D_{task_id+1}$\",\n",
    "                  dir_path=\"../artefacts/toy_experiment\",\n",
    "                  file_name=f\"lp_predictions_after_k_{task_id+1}\",\n",
    "                  samples_of_tasks=[task_id])\n",
    "\n",
    "#Plot the final decision boundaries including all visited task sample\n",
    "generate_plot(input_xy=xy_tensor,\n",
    "              prediction_xy=model_lp_predictions_trained[-1],\n",
    "              title=f\"LP - final\",\n",
    "              dir_path=\"../artefacts/toy_experiment\",\n",
    "              file_name=\"lp_final_decision_boundaries\",\n",
    "              samples_of_tasks=[0, 1, 2, 3])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, we'll see what would happen if we insert a Discrete Key-Value Bottleneck and combine it with our decoder architecture"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "args = Dict()\n",
    "args.num_pairs = 400\n",
    "args.cl_epochs = 1000\n",
    "args.init_epochs = 1000\n",
    "args.num_codebooks = 1\n",
    "args.input_dims = 2\n",
    "args.dim_value = 8\n",
    "args.dim_key = 2\n",
    "args.topk = 1\n",
    "args.num_classes = 8\n",
    "args.ff_dropout = 0.0\n",
    "\n",
    "decoder = CodebookVotingLogitsDecoder(dim_values=args.num_classes,\n",
    "                                       class_nums=args.num_classes,\n",
    "                                       args=args\n",
    "                                       )\n",
    "\n",
    "bottlenecked_encoder = kv_core.BottleneckedEncoder(encoder=nn.Identity(),\n",
    "                                                   num_codebooks=args.num_codebooks,\n",
    "                                                   num_channels=args.input_dims,\n",
    "                                                   key_value_pairs_per_codebook=args.num_pairs,\n",
    "                                                   dim_keys=args.dim_key,\n",
    "                                                   dim_values=decoder.dim_values,\n",
    "                                                   splitting_mode=\"chunk\",\n",
    "                                                   return_values_only=False,\n",
    "                                                   encoder_is_channel_last=False,\n",
    "                                                   concat_values_from_all_codebooks=False)\n",
    "\n",
    "values = 0.001*torch.randn_like(bottlenecked_encoder.bottleneck.values)\n",
    "bottlenecked_encoder.bottleneck.values = nn.Parameter(values)\n",
    "bottlenecked_encoder.bottleneck.values.requires_grad = True\n",
    "\n",
    "model_kv = KVModel(bottlenecked_encoder=bottlenecked_encoder,\n",
    "                   decoder=decoder,\n",
    "                   args=args)\n",
    "\n",
    "for _ in range(args.init_epochs):\n",
    "    model_kv(sample_key_init_data(100))\n",
    "bottlenecked_encoder.freeze_keys()\n",
    "bottlenecked_encoder.disable_update_keys()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We first plot the decision boundaries of our model with keys initialized on random input data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%capture\n",
    "xy_tensor = get_grid_samples_from_unit_square()\n",
    "model_kv_predictions = torch.argmax(model_kv(xy_tensor[:, 0, :]), dim=-1)\n",
    "generate_plot(input_xy=xy_tensor,\n",
    "              prediction_xy=model_kv_predictions,\n",
    "              title=\"KV - after init\",\n",
    "              dir_path=\"../artefacts/toy_experiment\",\n",
    "              file_name=\"kv_chunk_dec1_predictions_after_init\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, we'll see how the decision boundaries change when trained on the data stream"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%capture\n",
    "bottlenecked_encoder.reset_cluster_size_counter()\n",
    "bottlenecked_encoder.activate_counts()\n",
    "model_kv.train()\n",
    "optimizer_model_kv = torch.optim.Adam(model_kv.parameters(), lr=0.001)\n",
    "\n",
    "model_state_dicts = []\n",
    "for task_id in tqdm.tqdm(range(4)):\n",
    "    train_inputs, targets = get_train_stream_data(task_id)\n",
    "    for epoch in range(args.cl_epochs):\n",
    "        optimizer_model_kv.zero_grad()\n",
    "        outputs = model_kv(train_inputs[:, 0, :])\n",
    "        loss = nn.CrossEntropyLoss()(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer_model_kv.step()\n",
    "    model_state_dicts.append(deepcopy(model_kv.state_dict()))\n",
    "\n",
    "model_kv.eval()\n",
    "bottlenecked_encoder.deactivate_counts()\n",
    "model_kv_predictions_trained = []\n",
    "for task_id in range(4):\n",
    "    model_kv.load_state_dict(model_state_dicts[task_id])\n",
    "    model_kv_predictions_trained.append(torch.argmax(model_kv(xy_tensor[:, 0, :]), dim=-1))\n",
    "    generate_plot(input_xy=xy_tensor,\n",
    "                  prediction_xy=model_kv_predictions_trained[task_id],\n",
    "                  title=f\"KV - after $D_{task_id+1}$\",\n",
    "                  dir_path=\"../artefacts/toy_experiment\",\n",
    "                  file_name=f\"kv_chunk_dec1_predictions_after_k_{task_id+1}\",\n",
    "                  samples_of_tasks=[task_id])\n",
    "\n",
    "#Plot the final decision boundaries including all visited task sample\n",
    "generate_plot(input_xy=xy_tensor,\n",
    "              prediction_xy=model_kv_predictions_trained[-1],\n",
    "              title=f\"KV - final\",\n",
    "              dir_path=\"../artefacts/toy_experiment\",\n",
    "              file_name=\"kv_chunk_dec1_final_decision_boundaries\",\n",
    "              samples_of_tasks=[0, 1, 2, 3])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Finally, we'll investigate what would happen if we would use random projections and 20 codebooks with 20 key-value pairs each"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "args = Dict()\n",
    "args.num_pairs = 20\n",
    "args.cl_epochs = 1000\n",
    "args.init_epochs = 1000\n",
    "args.num_codebooks = 20\n",
    "args.input_dims = 2\n",
    "args.dim_value = 8\n",
    "args.dim_key = 2\n",
    "args.topk = 1\n",
    "args.num_classes = 8\n",
    "args.ff_dropout = 0.0\n",
    "\n",
    "decoder = CodebookVotingLogitsDecoder(dim_values=args.num_classes,\n",
    "                                       class_nums=args.num_classes,\n",
    "                                       args=args\n",
    "                                       )\n",
    "\n",
    "bottlenecked_encoder = kv_core.BottleneckedEncoder(encoder=nn.Identity(),\n",
    "                                                   num_codebooks=args.num_codebooks,\n",
    "                                                   num_channels=args.input_dims,\n",
    "                                                   key_value_pairs_per_codebook=args.num_pairs,\n",
    "                                                   dim_keys=args.dim_key,\n",
    "                                                   dim_values=decoder.dim_values,\n",
    "                                                   splitting_mode=\"random_projection\",\n",
    "                                                   return_values_only=False,\n",
    "                                                   encoder_is_channel_last=False,\n",
    "                                                   concat_values_from_all_codebooks=False)\n",
    "\n",
    "values = 0.001*torch.randn_like(bottlenecked_encoder.bottleneck.values)\n",
    "bottlenecked_encoder.bottleneck.values = nn.Parameter(values)\n",
    "bottlenecked_encoder.bottleneck.values.requires_grad = True\n",
    "\n",
    "model_kv = KVModel(bottlenecked_encoder=bottlenecked_encoder,\n",
    "                   decoder=decoder,\n",
    "                   args=args)\n",
    "\n",
    "for _ in range(args.init_epochs):\n",
    "    model_kv(sample_key_init_data(100))\n",
    "bottlenecked_encoder.freeze_keys()\n",
    "bottlenecked_encoder.disable_update_keys()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%capture\n",
    "xy_tensor = get_grid_samples_from_unit_square()\n",
    "model_kv_predictions = torch.argmax(model_kv(xy_tensor[:, 0, :]), dim=-1)\n",
    "generate_plot(input_xy=xy_tensor,\n",
    "              prediction_xy=model_kv_predictions,\n",
    "              title=\"KV - after init\",\n",
    "              dir_path=\"../artefacts/toy_experiment\",\n",
    "              file_name=\"kv_random_dec1_predictions_after_init\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%capture\n",
    "bottlenecked_encoder.reset_cluster_size_counter()\n",
    "bottlenecked_encoder.activate_counts()\n",
    "model_kv.train()\n",
    "for p in model_kv.parameters():\n",
    "    p.requires_grad = False\n",
    "bottlenecked_encoder.bottleneck.values.requires_grad = True\n",
    "bottlenecked_encoder.disable_update_keys()\n",
    "optimizer_model_kv = torch.optim.Adam(model_kv.parameters(), lr=0.001)\n",
    "\n",
    "model_state_dicts = []\n",
    "for task_id in range(4):\n",
    "    train_inputs, targets = get_train_stream_data(task_id)\n",
    "    for epoch in range(1000):\n",
    "        optimizer_model_kv.zero_grad()\n",
    "        outputs = model_kv(train_inputs[:, 0, :])\n",
    "        loss = nn.CrossEntropyLoss()(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer_model_kv.step()\n",
    "    model_state_dicts.append(deepcopy(model_kv.state_dict()))\n",
    "\n",
    "model_kv.eval()\n",
    "bottlenecked_encoder.deactivate_counts()\n",
    "model_kv_predictions_trained = []\n",
    "for task_id in range(4):\n",
    "    model_kv.load_state_dict(model_state_dicts[task_id])\n",
    "    model_kv_predictions_trained.append(torch.argmax(model_kv(xy_tensor[:, 0, :]), dim=-1))\n",
    "    generate_plot(input_xy=xy_tensor,\n",
    "                  prediction_xy=model_kv_predictions_trained[task_id],\n",
    "                  title=f\"KV - after $D_{task_id+1}$\",\n",
    "                  dir_path=\"../artefacts/toy_experiment\",\n",
    "                  file_name=f\"kv_random_dec1_predictions_after_k_{task_id+1}\",\n",
    "                  samples_of_tasks=[task_id])\n",
    "\n",
    "#Plot the final decision boundaries including all visited task sample\n",
    "generate_plot(input_xy=xy_tensor,\n",
    "              prediction_xy=model_kv_predictions_trained[-1],\n",
    "              title=f\"KV - final\",\n",
    "              dir_path=\"../artefacts/toy_experiment\",\n",
    "              file_name=\"kv_random_dec1_final_decision_boundaries\",\n",
    "              samples_of_tasks=[0, 1, 2, 3])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
