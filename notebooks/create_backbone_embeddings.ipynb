{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1330c6-553d-444b-81bb-bcdcfbca5e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kv_bottleneck_experiments.utils.model as model_utils\n",
    "import kv_bottleneck_experiments.utils.data as data_utils\n",
    "\n",
    "import key_value_bottleneck.core as kv_core\n",
    "\n",
    "from addict import Dict\n",
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ROOT_DIR = os.environ.get(\"PROJECT_ROOT_DIR\", None)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436c2a1a-5054-456d-b152-2700deee7b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "args_dict = {\"method\": \"ours\",\n",
    "             \"seed\": 0,\n",
    "             \"batch_size\": 256,\n",
    "             \"num_workers\": 0,\n",
    "             \"dim_key\": 16,\n",
    "             \"dim_value\": 8,\n",
    "             \"topk\": 1,\n",
    "             \"t_mode\": \"uniform_importance\",\n",
    "             \"scaling_mode\": \"free_num_keys\",\n",
    "             \"threshold_factor\": 0.1,\n",
    "             \"accept_image_fmap\": False,\n",
    "             \"init_mode\": \"random\",\n",
    "             \"num_pairs\": 10,\n",
    "             \"num_books\": 128,\n",
    "             \"decay\": 0.95,\n",
    "             \"splitting_mode\": \"random_projection\",\n",
    "             \"root_dir\": ROOT_DIR,\n",
    "             \"sample_codebook_temperature\": 0,\n",
    "             }\n",
    "\n",
    "args = Dict(args_dict)\n",
    "args.dataset_name = \"CIFAR10\"\n",
    "args.pretrain_layer = 3\n",
    "args.backbone = \"clip_vit_b32\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc507a13-3b56-46fd-9672-c803d40fde61",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in [\"STL10\", \"CIFAR10\", \"CIFAR100\"]:\n",
    "    for backbone in [\"swav_resnet50w2\", \"dino_resnet50\", \"clip_vit_b32\", \"resnet50_imagenet_v2\"]:\n",
    "        for pretrain_layer in [3, 4]:\n",
    "            args.dataset_name = dataset\n",
    "            args.pretrain_layer = pretrain_layer\n",
    "            args.backbone = backbone\n",
    "\n",
    "            dataloader_train, dataloader_test = data_utils.get_dataloaders(\n",
    "                dataset=dataset, args=args\n",
    "            )\n",
    "            key_value_pairs_per_codebook = model_utils.get_key_value_pairs_per_codebook(args)\n",
    "            threshold_ema_dead_code = model_utils.get_threshold_ema_dead_code(args)\n",
    "\n",
    "            if \"cifar10\" in args.backbone or \"cifar100\" in args.backbone:\n",
    "                bottleneck_encoder_cls = kv_core.SLPretrainedBottleneckedEncoder\n",
    "            elif args.backbone == \"resnet50_imagenet_v2\":\n",
    "                bottleneck_encoder_cls = kv_core.SLPretrainedBottleneckedEncoder\n",
    "            elif args.backbone == \"clip_vit_b32\":\n",
    "                bottleneck_encoder_cls = kv_core.CLIPBottleneckedEncoder\n",
    "            elif \"swav\" in args.backbone:\n",
    "                bottleneck_encoder_cls = kv_core.SwavBottleneckedEncoder\n",
    "            else:\n",
    "                bottleneck_encoder_cls = kv_core.DinoBottleneckedEncoder\n",
    "\n",
    "            dim_values = args.dim_value\n",
    "\n",
    "            bottlenecked_encoder = bottleneck_encoder_cls(\n",
    "                num_codebooks=args.num_books,\n",
    "                key_value_pairs_per_codebook=key_value_pairs_per_codebook,\n",
    "                backbone=args.backbone,\n",
    "                extracted_layer=args.pretrain_layer,\n",
    "                pool_embedding=not args.accept_image_fmap,\n",
    "                init_mode=args.init_mode,\n",
    "                splitting_mode=args.splitting_mode,\n",
    "                dim_values=dim_values,\n",
    "                dim_keys=args.dim_key,\n",
    "                decay=args.decay,\n",
    "                eps=1e-5,\n",
    "                threshold_ema_dead_code=threshold_ema_dead_code,\n",
    "                concat_values_from_all_codebooks=False,\n",
    "                sample_codebook_temperature=args.sample_codebook_temperature,\n",
    "                return_values_only=False,\n",
    "                topk=args.topk,\n",
    "            )\n",
    "            bottlenecked_encoder = bottlenecked_encoder.freeze_encoder()\n",
    "            bottlenecked_encoder.eval()\n",
    "            deviating_transforms = None\n",
    "            if bottlenecked_encoder.transforms is not None:\n",
    "                deviating_transforms = bottlenecked_encoder.transforms\n",
    "                if isinstance(dataloader_train, torch.utils.data.DataLoader):\n",
    "                    dataloader_train.dataset.transform = deviating_transforms\n",
    "                    dataloader_test.dataset.transform = deviating_transforms\n",
    "\n",
    "            bottlenecked_encoder.to(device)\n",
    "\n",
    "            data_utils.create_embedding_dataset(\n",
    "                dataloader_train, dataloader_test, bottlenecked_encoder, args\n",
    "            )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
